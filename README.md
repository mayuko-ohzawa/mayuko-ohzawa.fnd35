# MyEmolog - Track my emotion
自分の感情を記録し，客観的に分析することで，感情や行動のパターンの理解を促します。これによって，自己理解を深め，アンガーマネジメントやストレス/不安の軽減を図ることが期待されます。  

## 機能  
音声を入力するとそのテキスト情報から感情を認識し，その結果を元にチャットボットが反応します。また，発話内容とその感情をログとして記録し，発話をwavファイルとして自動ダウンロードします。  
音声認識にはWeb SpeechRecognition API，感情認識にはGoogle Natural Language API，チャットボットにはopenAI APIを使用しています。  

## 使い方  
1. 「Rec. START」をクリックし，ブラウザに向かって喋ってください。
2. 喋り終えたら「Rec. STOP」をクリックしてください。クリック後にwavファイルがダウンロードされます。
3. 「Emotion log」に表示される発話内容はいつでも修正可能です。修正が必要な場合は適宜修正してください。  

※Web SpeechRecognition APIはブラウザによっては機能しない可能性があります。  
※Google Natural Language APIはセキュリティの観点からAPIキーを指定していないため，Github Pages上では機能しません。  
※openAI APIはアクセスが集中している場合は機能しません。

## 工夫した点
1. 後から分析できるように収録音声をダウンロード
2. openAI APIのアクセスが集中して応答しない場合に，感情ごとに決まったセリフで返答
3. 音声が誤って認識された場合に，発話内容を後から修正できるように実装

## 苦労した点 
1. APIからデータ取得：所望の動きをさせること
2. デザイン面：ブラウザにどのように表示させるか

## 改善点
1. 音声録音中と分かるように波形アニメーションを追加
2. 音声ファイルやログをクラウドに保存して管理
3. クラウドに蓄積させたデータを用いてパーソナル感情認識モデルを構築
4. 表情（顔画像）や音声の音響的特徴などを用いたマルチモーダル感情認識（現時点ではテキスト情報のみ）
5. 認識できる感情を追加（現在はjoy/sad/anger/neutralの4感情のみ）
