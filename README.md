【機能】  
音声を入力するとそのテキスト情報から感情を認識し，その結果を元にチャットボットが反応します。また，発話内容とその感情をログとして記録し，発話をwavファイルとして自動ダウンロードします。  
音声認識にはWeb SpeechRecognition API，感情認識にはGoogle Natural Language API，チャットボットにはopenAI APIを使用しています。  
  
【目的】  
自分の感情を記録し，客観的に分析することで，感情や行動のパターンの理解を促します。これによって，自己理解を深め，アンガーマネジメントやストレス/不安の軽減を図ることが期待されます。  
  
【使い方】  
1. 「Rec. START」をクリックし，ブラウザに向かって喋ってください。
2. 喋り終えたら「Rec. STOP」をクリックしてください。クリック後にwavファイルがダウンロードされます。
3. 「Emotion log」に表示される発話内容はいつでも修正可能です。修正が必要な場合は適宜修正してください。  

※Web SpeechRecognition APIはブラウザによっては機能しない可能性があります。  
※Google Natural Language APIはセキュリティの観点からAPIキーを指定していないため，Github Pages上では機能しません。  
※openAI APIはアクセスが集中している場合は機能しません。
  
【作成にあたって苦労した点】  
1. APIからデータ取得：所望の動きをさせること
2. デザイン面：ブラウザにどのように表示させるか

【今後の展望】  
1. 音声ファイルやログをクラウドに保存して管理
2. クラウドに蓄積させたデータを用いてパーソナル感情認識モデルを構築
3. 表情（顔画像）や音声の音響的特徴などを用いたマルチモーダル感情認識（現時点ではテキスト情報のみ）
4. 認識できる感情を追加（現在はjoy/sad/anger/neutralの4感情のみ）
